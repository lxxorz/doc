学习信息论前需要对概率论有一定的掌握，因此必须对一下概念非常熟悉
### 数学期望
每个可能的值乘以概率的总和，所以也被称为**均值**${\displaystyle {\bar {x}}_{j}={\frac {1}{N}}\sum _{i=1}^{N}x_{ij},\quad j=1,\ldots ,K.}$

### 方差
描述一个随机变量的离散程度
如果是连续的随机变量，假设 $E (X)$ 是随机变量 X 的期望值，那么随机变量的方差是，
$$
Var(X)= E[(X-u)^2]
 =E(X^2)-(E(X))^2
$$

